{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aba351-aa2b-40f8-9d22-87d3fc95774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "#Load index list\n",
    "Year=1938\n",
    "Showa=13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a775b5-c95a-4928-9e56-0f3945c63228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Function\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d46eb6-bd84-4868-87bf-b784389adade",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLOVA FUNCTION ###\n",
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "api_url = 'https://deelieyxuc.apigw.ntruss.com/custom/v1/1972/ebd01bcbf693d069817622e9839e20914143c7d0d8953eddee40e8b0af96c95b/general'\n",
    "secret_key = 'S1NmVXpYZlJ0cGJ0ZEFRZXVlbkRkaHFReE9FcHNTQ0U='\n",
    "\n",
    "def Clova(Image):\n",
    "    request_json = {\n",
    "            'images': [\n",
    "                {\n",
    "                    'format': 'jpg',\n",
    "                    'name': 'demo',\n",
    "                    'data':base64.b64encode(file_data).decode()}],\n",
    "            'requestId': str(uuid.uuid4()),\n",
    "            'version': 'V2',\n",
    "            'timestamp': int(round(time.time() * 1000)),\n",
    "            'lang':'ja'\n",
    "            }\n",
    "    payload = json.dumps(request_json).encode(\"UTF-8\")\n",
    "    headers = {'X-OCR-SECRET': secret_key,\n",
    "              'Content-Type': 'application/json'}\n",
    "    response = requests.request(\"POST\", api_url, headers=headers, data = payload)\n",
    "    Json=json.loads(response.text)['images'][0]\n",
    "    \n",
    "    return Json    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b858353-6046-4bd6-bcc9-3bdbc226b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Cell\n",
    "def GetCell(cropped):\n",
    "    #Code for Adding Grid\n",
    "        ##Right page\n",
    "        img = cropped.copy()\n",
    "        hh, ww = img.shape[:2]\n",
    "\n",
    "        #Identify grid location\n",
    "        ## convert to grayscale\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # threshold gray image\n",
    "        thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        ## count number of non-zero pixels in each column and row. \n",
    "        countCol = np.count_nonzero(thresh, axis=0)\n",
    "        countRow = np.count_nonzero(thresh, axis=1)\n",
    "\n",
    "        ###############\n",
    "        ## Column lines\n",
    "        ###############\n",
    "        ### This finds the height of the smallest peak\n",
    "        peaksCol, _ = find_peaks(countCol, distance=10)\n",
    "        ### threshold count at Thres\n",
    "        count_thresh = countCol.copy()\n",
    "        count_thresh[peaksCol] = 255\n",
    "        count_thresh[count_thresh!=255] = 0\n",
    "        count_thresh = count_thresh.astype(np.uint8)\n",
    "\n",
    "        ### get contours\n",
    "        contoursCol = cv2.findContours(count_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contoursCol = contoursCol[0] if len(contoursCol) == 2 else contoursCol[1]\n",
    "\n",
    "        ### loop over contours and get bounding boxes and ycenter and draw horizontal line at ycenter\n",
    "        result = cropped.copy()\n",
    "        for cntr in contoursCol:\n",
    "            x,y,w,h = cv2.boundingRect(cntr)\n",
    "            ycenter = y\n",
    "            cv2.line(result, (ycenter,0), (ycenter,hh), (255, 0, 0), 1)\n",
    "        \n",
    "\n",
    "        ###############\n",
    "        ## Row lines\n",
    "        ###############\n",
    "        peaksRow, _ = find_peaks(countRow, distance=60)\n",
    "        ### threshold count at Thres\n",
    "        count_thresh = countRow.copy()\n",
    "        count_thresh[peaksRow] = 255\n",
    "        count_thresh[count_thresh!=255] = 0\n",
    "        count_thresh = count_thresh.astype(np.uint8)\n",
    "\n",
    "        ### get contours\n",
    "        contoursRow = cv2.findContours(count_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contoursRow = contoursRow[0] if len(contoursRow) == 2 else contoursRow[1]\n",
    "\n",
    "        ### loop over contours and get bounding boxes and ycenter and draw horizontal line at ycenter\n",
    "        for cntr in contoursRow:\n",
    "            x,y,w,h = cv2.boundingRect(cntr)\n",
    "            ycenter = y+h//2\n",
    "            cv2.line(result, (0,ycenter), (hh,ycenter), (255, 0, 0), 1)\n",
    "                \n",
    "        return(peaksRow,peaksCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da85bc03-2a62-47f1-8185-82b0b79c740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract(Position,ImageNumber):\n",
    "    path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Office_Level\\\\\"+Year+\"\\\\\"+Dept+\"\\\\\"+Office+\"\\\\\"+Unit+\"\\\\\"+Position+\"\\\\\"\n",
    "    stream = open(path+\"Image\"+str(ImageNumber)+'.png', \"rb\")\n",
    "    bytes = bytearray(stream.read())\n",
    "    numpyarray = np.asarray(bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    HH,WW=img.shape[:2]\n",
    "    \n",
    "    dfA = pd.DataFrame(columns = ['Name', 'Wage'])\n",
    "    dfT = pd.DataFrame(columns = ['Name', 'Wage'])\n",
    "    dfB = pd.DataFrame(columns = ['Name', 'Wage'])\n",
    "    \n",
    "    if Position==\"Admin\":\n",
    "        cropped=img[0:HH//2,0:WW]\n",
    "        MiddleLineList=GetCell(cropped)[0]\n",
    "        res = list(map(abs, [d-HH//4 for d in MiddleLineList.tolist()]))\n",
    "        minpos = res.index(min(res))\n",
    "\n",
    "        MiddleLine=MiddleLineList[minpos]\n",
    "        ColumnLine=GetCell(cropped)[1]\n",
    "        \n",
    "        ##Top Chunk ##\n",
    "        path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Temp\\\\\"\n",
    "        HH,WW=cropped.shape[:2]\n",
    "        for Line in ColumnLine.tolist():\n",
    "            if Line==ColumnLine.tolist()[0]:\n",
    "                #Wage\n",
    "                Image=cropped[0:MiddleLine,0:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Wage='NA'\n",
    "                else:\n",
    "                    Wage=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Name\n",
    "                Image=cropped[MiddleLine:HH,0:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Name='NA'\n",
    "                else:\n",
    "                    Name=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Add to DF\n",
    "                df2 = {'Name': Name, 'Wage': Wage}\n",
    "                dfT = dfT.append(df2, ignore_index = True)\n",
    "            else:\n",
    "                #Wage\n",
    "                Image=cropped[0:MiddleLine,Line-15:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Wage='NA'\n",
    "                else:\n",
    "                    Wage=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Name\n",
    "                Image=cropped[MiddleLine:HH,Line-15:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Name='NA'\n",
    "                else:\n",
    "                    Name=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Add to DF\n",
    "                df2 = {'Name': Name, 'Wage': Wage}\n",
    "                dfT = dfT.append(df2, ignore_index = True)\n",
    "\n",
    "        ##Bottom Chunk##\n",
    "        cropped=img[HH//2:HH,0:WW]\n",
    "        HH,WW=cropped.shape[:2]\n",
    "        MiddleLineList=GetCell(cropped)[0]\n",
    "        res = list(map(abs, [d-HH//4 for d in MiddleLineList.tolist()]))\n",
    "        minpos = res.index(min(res))\n",
    "        MiddleLine=MiddleLineList[minpos]\n",
    "        ColumnLine=GetCell(cropped)[1]\n",
    "        \n",
    "        path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Temp\\\\\"\n",
    "        for Line in ColumnLine.tolist():\n",
    "            if Line==ColumnLine.tolist()[0]:\n",
    "                #Wage\n",
    "                Image=cropped[0:MiddleLine,0:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Wage='NA'\n",
    "                else:\n",
    "                    Wage=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Name\n",
    "                Image=cropped[MiddleLine:HH,0:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Name='NA'\n",
    "                else:\n",
    "                    Name=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Add to DF\n",
    "                df2 = {'Name': Name, 'Wage': Wage}\n",
    "                dfB = dfB.append(df2, ignore_index = True)\n",
    "            else:\n",
    "                #Wage\n",
    "                Image=cropped[0:MiddleLine,Line-15:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Wage='NA'\n",
    "                else:\n",
    "                    Wage=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Name\n",
    "                Image=cropped[MiddleLine:HH,Line-15:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Name='NA'\n",
    "                else:\n",
    "                    Name=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Add to DF\n",
    "                #Add to DF\n",
    "                df2 = {'Name': Name, 'Wage': Wage}\n",
    "                dfB = dfB.append(df2, ignore_index = True)\n",
    "        return pd.concat([dfT,dfB], ignore_index = True)\n",
    "    \n",
    "    else:\n",
    "        cropped=img\n",
    "\n",
    "        HH,WW=cropped.shape[:2]\n",
    "        MiddleLineList=GetCell(cropped)[0]\n",
    "        res = list(map(abs, [d-HH//2 for d in MiddleLineList.tolist()]))\n",
    "        minpos = res.index(min(res))\n",
    "        MiddleLine=MiddleLineList[minpos]\n",
    "        ColumnLine=GetCell(cropped)[1].tolist()\n",
    "        \n",
    "        path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Temp\\\\\"\n",
    "        for Line in ColumnLine:\n",
    "            if Line==ColumnLine[0]:\n",
    "                #Wage\n",
    "                Image=cropped[0:MiddleLine,0:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Wage='NA'\n",
    "                else:\n",
    "                    Wage=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Name\n",
    "                Image=cropped[MiddleLine:HH,0:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Name='NA'\n",
    "                else:\n",
    "                    Name=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Add to DF\n",
    "                df2 = {'Name': Name, 'Wage': Wage}\n",
    "                dfA = dfA.append(df2, ignore_index = True)\n",
    "\n",
    "            else:\n",
    "                #Wage\n",
    "                Image=cropped[0:MiddleLine,Line-15:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Wage='NA'\n",
    "                else:\n",
    "                    Wage=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "                #Name\n",
    "                Image=cropped[MiddleLine:HH,Line-15:Line]\n",
    "                cv2.imwrite(path+\"Temp.jpg\",Image)\n",
    "                with open(path+\"Temp.jpg\",'rb') as f:\n",
    "                    file_data = f.read()\n",
    "                Json=Clova(file_data)\n",
    "                if Json['inferResult']=='ERROR':\n",
    "                    Name='NA'\n",
    "                else:\n",
    "                    Name=''.join([d['inferText'] for d in Json['fields']])\n",
    "\n",
    "\n",
    "                #Add to DF\n",
    "                df2 = {'Name': Name, 'Wage': Wage}\n",
    "                dfA = dfA.append(df2, ignore_index = True)\n",
    "        return(dfA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aebec7cd-0a64-47c0-99e7-ca89b7833d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data Frame\n",
    "path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Processed_Data\\\\\"+str(Year)+\"\\\\DataFrame.json\"\n",
    "with open(path, 'r') as j:\n",
    "     dta = json.loads(j.read())\n",
    "\n",
    "df = pd.read_csv(r'C:/Users/Keitaro Ninomiya/Box/Research Notes (keitaro2@illinois.edu)/Tokyo_Jobs/Processed_Data/Index/S'+str(Showa)+'.csv')\n",
    "df=df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8438db6e-cd4d-437a-85dd-d4945cf80a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'Admin', '文書課', 'Admin')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test code| Version 2#\n",
    "#Show Working office#\n",
    "n=1\n",
    "\n",
    "#Extract key info of office\n",
    "Row  = df.iloc[n]\n",
    "print(Row)\n",
    "###Collect Location information###\n",
    "Dept=Row[\"Dept\"]\n",
    "Office=Row[\"Office\"]\n",
    "PositionList=list(dta[str(Year)][Dept][Office]['Position'].keys())\n",
    "print(PositionList)\n",
    "\n",
    "for Position in PositionList:\n",
    "    StrPage=int(dta[str(Year)][Dept][Office]['Position'][Position]['Page'])\n",
    "    EndPage=int(dta[str(Year)][Dept][Office]['Position'][Position]['EndPage'])\n",
    "    PageList=list(set([1,EndPage-StrPage+1]))\n",
    "    print(Position)\n",
    "    for ImageNumber in PageList:        \n",
    "        print('Image Number is '+str(ImageNumber))\n",
    "        #Download Image\n",
    "        path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Office_Level\\\\\"+Year+\"\\\\\"+Dept+\"\\\\\"+Office+\"\\\\\"+Position+\"\\\\\"\n",
    "        try:\n",
    "            stream = open(path+\"Image\"+str(ImageNumber)+'.png', \"rb\")\n",
    "            bytes = bytearray(stream.read())\n",
    "            numpyarray = np.asarray(bytes, dtype=np.uint8)\n",
    "            img = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)\n",
    "        except:\n",
    "            print('Could not find image')\n",
    "            continue\n",
    "\n",
    "        HH,WW=img.shape[:2]\n",
    "\n",
    "        DF=pd.DataFrame(columns = ['Name', 'Wage'])\n",
    "        if Position=='Admin':\n",
    "            croppedTop=img[0:HH//2,0:WW]\n",
    "            cv2.imshow(\"Sample\",croppedTop)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "            croppedBtm=img[HH//2:HH,0:WW]\n",
    "            cv2.imshow(\"Sample\",croppedBtm)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            dta[str(Year)][Dept][Office]['Position'][Position]['Data']=Extract(Position,ImageNumber)\n",
    "\n",
    "        else:\n",
    "            cropped=img\n",
    "            cv2.imshow(\"Sample\",cropped)\n",
    "            cv2.waitKey(0)\n",
    "            \n",
    "            dta[str(Year)][Dept][Office]['Position'][Position]['Data']=Extract(Position,ImageNumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2dcda572-9034-4f94-a4e9-6ac47bdf4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test code| Version 2#\n",
    "#Show Working office#\n",
    "for n in range(1,len(df)):\n",
    "    #Extract key info of office\n",
    "    Row  = df.iloc[n]\n",
    "    print(Row)\n",
    "    ###Collect Location information###\n",
    "    Dept=Row[\"Dept\"]\n",
    "    Office=Row[\"Office\"]\n",
    "    try:\n",
    "        PositionList=list(dta[str(Year)][Dept][Office]['Position'].keys())\n",
    "    except:\n",
    "        continue\n",
    "    print(PositionList)\n",
    "\n",
    "    for Position in PositionList:\n",
    "        StrPage=int(dta[str(Year)][Dept][Office]['Position'][Position]['Page'])\n",
    "        EndPage=int(dta[str(Year)][Dept][Office]['Position'][Position]['EndPage'])\n",
    "        PageList=list(set([1,EndPage-StrPage+1]))\n",
    "        print(Position)\n",
    "        for ImageNumber in PageList:        \n",
    "            #Download Image\n",
    "            path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Office_Level\\\\\"+Year+\"\\\\\"+Dept+\"\\\\\"+Office+\"\\\\\"+Position+\"\\\\\"\n",
    "            try:\n",
    "                stream = open(path+\"Image\"+str(ImageNumber)+'.png', \"rb\")\n",
    "                bytes = bytearray(stream.read())\n",
    "                numpyarray = np.asarray(bytes, dtype=np.uint8)\n",
    "                img = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)\n",
    "            except:\n",
    "                print('Could not find image')\n",
    "                continue\n",
    "\n",
    "            HH,WW=img.shape[:2]\n",
    "\n",
    "            DF=pd.DataFrame(columns = ['Name', 'Wage'])\n",
    "            if Position=='Admin':\n",
    "                croppedTop=img[0:HH//2,0:WW]\n",
    "                croppedBtm=img[HH//2:HH,0:WW]\n",
    "                try:\n",
    "                    dta[str(Year)][Dept][Office]['Position'][Position]['Data']=Extract(Position,ImageNumber)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            else:\n",
    "                cropped=img\n",
    "                try:\n",
    "                    dta[str(Year)][Dept][Office]['Position'][Position]['Data']=Extract(Position,ImageNumber)\n",
    "                except:\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6115fed0-5a0f-41ca-a47e-67f638f1401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object = json.dumps(dta, indent=4,\n",
    "                        cls=NpEncoder)\n",
    "save_path='C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Processed_Data\\\\'\n",
    "with open(save_path+\"DataFrame.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
