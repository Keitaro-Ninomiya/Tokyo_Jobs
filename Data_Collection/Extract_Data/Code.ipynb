{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1aba351-aa2b-40f8-9d22-87d3fc95774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91d46eb6-bd84-4868-87bf-b784389adade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CLOVA(img):\n",
    "    return(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75571db6-528b-4539-bac5-84f702c9b3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421 357\n"
     ]
    }
   ],
   "source": [
    "#Import Mother dataframe\n",
    "dta=\n",
    "\n",
    "#Load list\n",
    "Year=\n",
    "Showa=\n",
    "path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Splited\\\\\"+Year+\"\\\\\"\n",
    "os.chdir(path)\n",
    "df = pd.read_csv(r'C:/Users/Keitaro Ninomiya/Box/Research Notes (keitaro2@illinois.edu)/Tokyo_Jobs/Processed_Data/Index/S'+Showa+'.csv')\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "\n",
    "for n in range(1,len(df[\"Office\"])):\n",
    "    img_list=dta[Year][Office]['Manager']\n",
    "    for i in range(0,img_list):\n",
    "        img=img_list[n]\n",
    "        \n",
    "        HH,WW=img.shape[:2]\n",
    "        cropped=img[0:HH//2,Edge2:Edge1]\n",
    "        cv2.imshow(\"CROP\",cropped)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        #Code for Adding Grid\n",
    "        ##Right page\n",
    "        img = cropped.copy()\n",
    "        hh, ww = img.shape[:2]\n",
    "\n",
    "        #Identify grid location\n",
    "        ## convert to grayscale\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # threshold gray image\n",
    "        thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        ## count number of non-zero pixels in each column and row. \n",
    "        countCol = np.count_nonzero(thresh, axis=0)\n",
    "        countRow = np.count_nonzero(thresh, axis=1)\n",
    "\n",
    "        ## Column lines\n",
    "        ### This finds the height of the smallest peak\n",
    "        peaksCol, _ = find_peaks(countCol, distance=15)\n",
    "        print(\"Column borders are...\")\n",
    "        print(peaksCol)\n",
    "        Thres=min(countCol[peaksCol])\n",
    "        ### threshold count at Thres\n",
    "        count_thresh = countCol.copy()\n",
    "        count_thresh[peaksCol] = 255\n",
    "        count_thresh[count_thresh!=255] = 0\n",
    "        count_thresh = count_thresh.astype(np.uint8)\n",
    "\n",
    "        ### get contours\n",
    "        contoursCol = cv2.findContours(count_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contoursCol = contoursCol[0] if len(contoursCol) == 2 else contoursCol[1]\n",
    "\n",
    "        ### loop over contours and get bounding boxes and ycenter and draw horizontal line at ycenter\n",
    "        result = cropped.copy()\n",
    "        for cntr in contoursCol:\n",
    "            x,y,w,h = cv2.boundingRect(cntr)\n",
    "            ycenter = y+h//2\n",
    "            cv2.line(result, (ycenter,0), (ycenter,hh), (255, 0, 0), 1)\n",
    "        \n",
    "        ##Collect Wage+Name info##\n",
    "        HH,WW=cropped.shape[:2]\n",
    "        Row=HH//2\n",
    "        Unit=pd.DataFrame()\n",
    "        Line_list=np.insert(peaksCol,0, 0)\n",
    "        for n in range(0,len(countCol)):\n",
    "            WagePic=cropped[0:Row,Line_list[n]:Line_list[n+1]]\n",
    "            Wage=Clova(WagePic)\n",
    "            ## Add code to extract wage from json##\n",
    "\n",
    "            NamePic=cropped[Row:HH,Line_list[n]:Line_list[n+1]]\n",
    "            Name=Clova(NamePic)\n",
    "            ## Add code to extract name from json##\n",
    "            Row=list((Wage,Name))\n",
    "            Unit=Unit.append(Row,ignore_index = True)\n",
    "        dta[Year][Office]['Manager']['Data'].append(Unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7e149f-1f4c-4649-83bb-9eb175a5deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Code 1#\n",
    "#Code for Detecting location of Clerks#\n",
    "# Opening JSON file\n",
    "file_path='C:/Users/Keitaro Ninomiya/Desktop/[Test_3]TextOCR[20230216213014].json'\n",
    "\n",
    "with open(file_path, encoding=\"utf-8\") as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "List=data['images'][0][\"fields\"]\n",
    "\n",
    "Office='書記'\n",
    "res = [d\n",
    "       for d in List \n",
    "       if d['inferText'] == Office]\n",
    "res = res[0]['boundingPoly']['vertices']\n",
    "Edge1=int(max([i['x'] for i in res]))\n",
    "\n",
    "Office='雇'\n",
    "res = [d\n",
    "       for d in List \n",
    "       if d['inferText'] == Office]\n",
    "res = res[0]['boundingPoly']['vertices']\n",
    "Edge2=int(max([i['x'] for i in res]))\n",
    "\n",
    "print(Edge1,Edge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e6b9429-a8eb-4098-b353-4d600841d8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Code 2#\n",
    "path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Splited\\\\1938\\\\\"\n",
    "os.chdir(path)\n",
    "\n",
    "#Set up parameters\n",
    "Year='1938'\n",
    "Page=51\n",
    "\n",
    "#Download data\n",
    "img=cv2.imread(\"Page\"+\"{:03d}\".format(Page)+\"\\\\\"+\"Page\"+\"{:03d}\".format(Page)+\".jpg\")\n",
    "HH,WW=img.shape[:2]\n",
    "cropped=img[0:HH//2,Edge2:Edge1]\n",
    "cv2.imshow(\"CROP\",cropped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a0bdb0d-c73e-459d-968c-4a54cd25355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column borders are...\n",
      "[17 32 47]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test Code 3#\n",
    "########################\n",
    "## Cut page into cells##\n",
    "########################\n",
    "HH,WW=img.shape[:2]\n",
    "cropped=img[0:HH//2,Edge2:Edge1]\n",
    "cv2.imshow(\"CROP\",cropped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "#Code for Adding Grid\n",
    "##Right page\n",
    "img = cropped.copy()\n",
    "hh, ww = img.shape[:2]\n",
    "\n",
    "#Identify grid location\n",
    "## convert to grayscale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# threshold gray image\n",
    "thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "## count number of non-zero pixels in each column and row. \n",
    "countCol = np.count_nonzero(thresh, axis=0)\n",
    "countRow = np.count_nonzero(thresh, axis=1)\n",
    "\n",
    "## Column lines\n",
    "### This finds the height of the smallest peak\n",
    "peaksCol, _ = find_peaks(countCol, distance=15)\n",
    "print(\"Column borders are...\")\n",
    "print(peaksCol)\n",
    "Thres=min(countCol[peaksCol])\n",
    "### threshold count at Thres\n",
    "count_thresh = countCol.copy()\n",
    "count_thresh[peaksCol] = 255\n",
    "count_thresh[count_thresh!=255] = 0\n",
    "count_thresh = count_thresh.astype(np.uint8)\n",
    "\n",
    "### get contours\n",
    "contoursCol = cv2.findContours(count_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contoursCol = contoursCol[0] if len(contoursCol) == 2 else contoursCol[1]\n",
    "\n",
    "### loop over contours and get bounding boxes and ycenter and draw horizontal line at ycenter\n",
    "result = cropped.copy()\n",
    "for cntr in contoursCol:\n",
    "    x,y,w,h = cv2.boundingRect(cntr)\n",
    "    ycenter = y+h//2\n",
    "    cv2.line(result, (ycenter,0), (ycenter,hh), (255, 0, 0), 1)\n",
    "\n",
    "# display results\n",
    "cv2.imshow(\"RESULT\", result)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7b6ebf-0aed-47a2-9b7b-e9dc047051f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Code 4#\n",
    "HH,WW=cropped.shape[:2]\n",
    "Row=HH//2\n",
    "Line_list=np.insert(peaksCol,0, 0)\n",
    "for n in range(0,len(peaksCol)):\n",
    "    WagePic=cropped[0:Row,Line_list[n]:Line_list[n+1]]\n",
    "    cv2.imwrite(r'C:/Users/Keitaro Ninomiya/Desktop/WagePic'+str(n)+'.png', WagePic,[cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "    cv2.imshow(\"CROP\",WagePic)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    NamePic=cropped[Row:HH,Line_list[n]:Line_list[n+1]]\n",
    "    cv2.imwrite(r'C:/Users/Keitaro Ninomiya/Desktop/NamePic'+str(n)+'.png', NamePic,[cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "    cv2.imshow(\"CROP\",NamePic)\n",
    "    cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
