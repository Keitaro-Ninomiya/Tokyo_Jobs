{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "461eb23e-8a5e-4b77-9c2a-7738c54ec4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "Year=\n",
    "Showa="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7daa5ab1-3258-4a66-babf-0b8fc889083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Detect_Unit(Json,Dept,Office):\n",
    "    NewList=Json['fields']\n",
    "    Dict=list()\n",
    "    for d in NewList:\n",
    "        try:\n",
    "            newDict={}\n",
    "            newDict['inferText']=d['inferText']\n",
    "            newDict['boundingPoly']=d['boundingPoly']\n",
    "            Dict.append(newDict)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    res = [d\n",
    "       for d in Dict \n",
    "       if ( d['inferText'][-1]=='掛')]\n",
    "\n",
    "    if len(res)!=0:\n",
    "        res = res[0]['boundingPoly']['vertices']\n",
    "        Edge=max(int(d['x']) for d in res)\n",
    "        return(Edge)\n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "### CLOVA FUNCTION ###\n",
    "import requests\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import base64\n",
    "\n",
    "api_url = 'https://deelieyxuc.apigw.ntruss.com/custom/v1/1972/ebd01bcbf693d069817622e9839e20914143c7d0d8953eddee40e8b0af96c95b/general'\n",
    "secret_key = 'S1NmVXpYZlJ0cGJ0ZEFRZXVlbkRkaHFReE9FcHNTQ0U='\n",
    "\n",
    "def Clova(Year,Office,Num):\n",
    "    path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Office_Level\\\\\"+Year+\"\\\\\"+Dept+\"\\\\\"+Office+\"\\\\\"\n",
    "    with open(path+\"Image\"+str(Num)+\".png\",'rb') as f:\n",
    "         file_data = f.read()\n",
    "\n",
    "    request_json = {\n",
    "            'images': [\n",
    "                {\n",
    "                    'format': 'jpg',\n",
    "                    'name': 'demo',\n",
    "                    'data':base64.b64encode(file_data).decode()}],\n",
    "            'requestId': str(uuid.uuid4()),\n",
    "            'version': 'V2',\n",
    "            'timestamp': int(round(time.time() * 1000)),\n",
    "            'lang':'ja'\n",
    "            }\n",
    "    payload = json.dumps(request_json).encode(\"UTF-8\")\n",
    "    headers = {'X-OCR-SECRET': secret_key,\n",
    "              'Content-Type': 'application/json'}\n",
    "    response = requests.request(\"POST\", api_url, headers=headers, data = payload)\n",
    "    Json=json.loads(response.text)['images'][0]\n",
    "    \n",
    "    return Json\n",
    "\n",
    "def Clova2(Year,Dept,Office,Num,LeftEdge,RightEdge):\n",
    "    path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Office_Level\\\\\"+Year+\"\\\\\"+Dept+\"\\\\\"+Office+\"\\\\\"\n",
    "    stream = open(path+\"Image\"+str(Num)+'.png', \"rb\")\n",
    "    bytes = bytearray(stream.read())\n",
    "    numpyarray = np.asarray(bytes, dtype=np.uint8)\n",
    "    img = cv2.imdecode(numpyarray, cv2.IMREAD_UNCHANGED)\n",
    "    HH,WW=img.shape[:2]\n",
    "    cropped=img[0:HH,LeftEdge:RightEdge]\n",
    "    \n",
    "    temp_path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Temp\\\\\"\n",
    "    cv2.imwrite(temp_path+\"Temp.jpg\",cropped)\n",
    "    with open(temp_path+\"Temp.jpg\",'rb') as f:\n",
    "        file_data = f.read()\n",
    "    \n",
    "    request_json = {\n",
    "            'images': [\n",
    "                {\n",
    "                    'format': 'jpg',\n",
    "                    'name': 'demo',\n",
    "                    'data':base64.b64encode(file_data).decode()}],\n",
    "            'requestId': str(uuid.uuid4()),\n",
    "            'version': 'V2',\n",
    "            'timestamp': int(round(time.time() * 1000)),\n",
    "            'lang':'ja'\n",
    "            }\n",
    "    payload = json.dumps(request_json).encode(\"UTF-8\")\n",
    "    headers = {'X-OCR-SECRET': secret_key,\n",
    "              'Content-Type': 'application/json'}\n",
    "    response = requests.request(\"POST\", api_url, headers=headers, data = payload)\n",
    "    Json=json.loads(response.text)['images'][0]\n",
    "    \n",
    "    return Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "d7c80ab2-9685-4629-961b-03dd44b4fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Location of units.\n",
    "def ExtractUnit(Year,Dept,Office):\n",
    "    Dict=list()\n",
    "    PageRange=dta[Year][Dept][Office]['Page_Range']\n",
    "    NumberList=list(range(PageRange[0]-PageRange[0]+1,PageRange[-1]-PageRange[0]+1+1))\n",
    "    \n",
    "    #Apply OCR and extract columns with unit names\n",
    "    for n in NumberList: \n",
    "        newDict=list()\n",
    "        Json=Clova(Year,Office,n)\n",
    "\n",
    "        NewList=Json['fields']\n",
    "        for d in NewList:\n",
    "            try:\n",
    "                newnewDict={}\n",
    "                newnewDict['inferText']=d['inferText']\n",
    "                newnewDict['boundingPoly']=d['boundingPoly']\n",
    "                newnewDict['Page']=int(n)\n",
    "                newDict.append(newnewDict)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "        res = [d['boundingPoly']\n",
    "           for d in newDict \n",
    "           if d['inferText'][-1]=='掛']\n",
    "\n",
    "        for col in res:\n",
    "            col2=col['vertices']\n",
    "            EdgeL=min(d['x'] for d in col2)\n",
    "            EdgeR=max(d['x'] for d in col2)\n",
    "            col['EdgeL']=int(EdgeL)\n",
    "            col['EdgeR']=int(EdgeR+5)\n",
    "            col['Page']=int(n)\n",
    "            col['vertices']=None\n",
    "        Dict.append(res)\n",
    "    \n",
    "    #Reformat OCR-ed Image into dictionary\n",
    "    Count=0\n",
    "    for page in Dict:\n",
    "        if page==[]:\n",
    "            continue\n",
    "        Page=page[0]['Page']\n",
    "        for unit in page:\n",
    "            try:\n",
    "                LeftEdge,RightEdge=unit['EdgeL'],unit['EdgeR']\n",
    "                Json=Clova2(Year,Dept,Office,Page,LeftEdge,RightEdge)\n",
    "                for element in Json['fields']:\n",
    "                    res = element['boundingPoly']['vertices']\n",
    "                    TopY=max(int(d['y']) for d in res)\n",
    "                    BtmY=min(int(d['y']) for d in res)\n",
    "                    element['YCenter']=(TopY+BtmY)//2\n",
    "\n",
    "                NameList=sorted(Json['fields'], key=lambda d: d['YCenter']) \n",
    "                Text=''.join([element['inferText'] for element in NameList])\n",
    "                unit['Text']=Text.split('掛')[0]+'掛'\n",
    "            except:\n",
    "                continue\n",
    "        newpage={x['Text']:{'Page':x['Page'],'StartLocation':x['EdgeR']} for x in page}\n",
    "        Dict[Count]=newpage\n",
    "        Count=Count+1\n",
    "    \n",
    "    #Concatate into single nested dictionary\n",
    "    for page in Dict:    \n",
    "        Dict[0].update(page)\n",
    "    \n",
    "    return (Dict,Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c80734-76d6-4bb6-9ee1-8b9c180f261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organize(Dict):\n",
    "    UnitList=list(Dict[0].keys())\n",
    "    PageList=[]\n",
    "    for Unit in UnitList:\n",
    "        Page=Dict[0][Unit]['Page']\n",
    "        PageList.append(Page)\n",
    "    XEnd=0.0\n",
    "    EndPage=max(PageList)\n",
    "\n",
    "    Frame=pd.DataFrame.from_dict(Dict[0],orient='index')\n",
    "    Frame=Frame.sort_values(by = ['Page', 'StartLocation'], ascending = [True, False])\n",
    "    Frame['EndPage']=Frame['Page'].shift(periods=-1)[:-1].astype(int)\n",
    "    Frame['EndLocation']=Frame['StartLocation'].shift(periods=-1)[:-1].astype(int)\n",
    "    Frame['EndPage'][-1]=float(EndPage)\n",
    "    Frame['EndPage']=Frame['EndPage'].astype(int)\n",
    "    Frame['EndLocation'][-1]=float(XEnd)\n",
    "    Frame['EndLocation']=Frame['EndLocation'].astype(int)\n",
    "    \n",
    "    Frame.index = Frame.index.map(str)\n",
    "    Frame.columns = Frame.columns.map(str)\n",
    "    js = str(Frame.to_dict(orient='index')).replace(\"'\", '\"')\n",
    "\n",
    "    return(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5b60e940-c1cd-4684-ba97-967aadd1b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Raw_Data\\\\Splited\\\\\"+Year+\"\\\\\"\n",
    "os.chdir(path)\n",
    "df = pd.read_csv(r'C:/Users/Keitaro Ninomiya/Box/Research Notes (keitaro2@illinois.edu)/Tokyo_Jobs/Processed_Data/Index/S'+Showa+'.csv')\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "\n",
    "file_path='C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Processed_Data\\\\'+Year+'\\\\DataFrame.json'\n",
    "with open(file_path, encoding=\"utf-8\") as f:\n",
    "    dta = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47424767-0635-4bf3-bbb8-ca9ffa9ff310",
   "metadata": {},
   "outputs": [],
   "source": [
    "FailedList=[]\n",
    "for n in range(0,len(df)):\n",
    "    Row  = df.iloc[n]\n",
    "    NxRow= df.iloc[n+1]\n",
    "\n",
    "    ###Collect Location information###\n",
    "    Dept=Row[\"Dept\"]\n",
    "    NxDept=NxRow[\"Dept\"]\n",
    "\n",
    "    Office=Row[\"Office\"]\n",
    "    NxOffice=NxRow[\"Office\"]\n",
    "\n",
    "    #Get info of units\n",
    "    try:        \n",
    "        #Get info of units\n",
    "        Dict=ExtractUnit(Year,Dept,Office)\n",
    "        Dict=json.loads(Organize(Dict[0]))\n",
    "        #Add info to dataframe\n",
    "        dta[Year][Dept][Office]['Units']=Dict\n",
    "        dta[Year][Dept][Office]['Units']['List']=list(Dict.keys())\n",
    "    except:\n",
    "        print('Error at '+Dept+\" \"+Office)\n",
    "        FailedList.append(list((Dept,Office)))\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a35e20-744b-415e-9d10-2c1725726612",
   "metadata": {},
   "outputs": [],
   "source": [
    "SuccessRate=len(FailedList)/len(df)\n",
    "if len(FailedList)/len(df)<0.2:\n",
    "    print('Fantastic!! Success Rate is '+str(1-(len(FailedList)/len(df))))\n",
    "else:\n",
    "    print('残念...Success Rate is '+str(1-(len(FailedList)/len(df))))\n",
    "\n",
    "DF=pd.read_csv('C:\\\\Users\\\\Keitaro Ninomiya\\\\Box\\\\Research Notes (keitaro2@illinois.edu)\\\\Tokyo_Jobs\\\\Processed_Data\\\\Records.csv')\n",
    "DF.loc[int(Year)-1934-1, 'Unit'] = SuccessRate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
